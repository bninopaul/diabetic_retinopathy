{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from subprocess import check_output\n",
    "import glob\n",
    "import cv2 as cv\n",
    "import multiprocessing as mp\n",
    "from itertools import repeat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook loads, preprocess and dumps the images and labels data in a numpy array object in pickle format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"../../.kaggle/diabetic_retinopathy_detection/\"\n",
    "train_labels = pd.read_csv(base_path+\"trainLabels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35126, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>level</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10_left</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10_right</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13_left</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13_right</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15_left</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      image  level  id\n",
       "0   10_left      0  10\n",
       "1  10_right      0  10\n",
       "2   13_left      0  13\n",
       "3  13_right      0  13\n",
       "4   15_left      1  15"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[\"id\"] = train_labels[\"image\"].apply(lambda x: x.split(\"_\")[0]).astype(int)\n",
    "print(train_labels.shape)\n",
    "train_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17563\n"
     ]
    }
   ],
   "source": [
    "#number of participants\n",
    "print(len(train_labels[\"id\"].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files = np.sort(glob.glob(base_path+\"train/*.jpeg\"))\n",
    "test_files = np.sort(glob.glob(base_path+\"test/*.jpeg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35126, 53576)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_files), len(test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_preprocess(img, row_size=700, col_size=700):\n",
    "    \"\"\"\n",
    "    Resize the img to (row_size, col_size, num_channels)\n",
    "    and normalize to values 0 to 1.\n",
    "    \"\"\"\n",
    "    img_new = cv.resize(img, (row_size, col_size), \n",
    "                        interpolation = cv.INTER_CUBIC)\n",
    "    img_new = cv.normalize(img_new, None, alpha = 0, beta = 1,\n",
    "                           norm_type = cv.NORM_MINMAX,\n",
    "                           dtype = cv.CV_32F)\n",
    "    return img_new\n",
    "\n",
    "def preprocess(arg):\n",
    "    \"\"\"\n",
    "    Returns the preprocessed image, image_name, and label\n",
    "    \"\"\"\n",
    "    train_labels, file = arg\n",
    "    img = cv.imread(file)\n",
    "    img = img_preprocess(img)\n",
    "    \n",
    "    img_nm = file.split(\"/\")[-1].split(\".\")[0]\n",
    "    label = train_labels[train_labels[\"image\"]==img_nm][\"level\"].iloc[0]\n",
    "    return img, img_nm, label\n",
    "\n",
    "def dump_preprocess(train_files, train_labels, num_per_batch=2000):\n",
    "    \n",
    "    num_batch = len(train_files)//num_per_batch \\\n",
    "                        if len(train_files)%num_per_batch==0\\\n",
    "                        else (len(train_files)//num_per_batch)+1\n",
    "    print(\"Number of Batches:\", num_batch)\n",
    "    for i in range(num_batch):\n",
    "        files_batch = train_files[i*num_per_batch: i*num_per_batch + num_per_batch]\n",
    "        pool = mp.Pool(processes=mp.cpu_count()-2)\n",
    "        res = pool.map(preprocess, zip(repeat(train_labels, len(files_batch)),\n",
    "                                       files_batch))\n",
    "        pool.close()\n",
    "        images = np.array([i[0] for i in res])\n",
    "        labels_ids = np.array([i[1:] for i in res])\n",
    "        pd.to_pickle(images, base_path+\"train_preprocessed/\"+\"images_%i.pkl\"%(i))\n",
    "        pd.to_pickle(labels_ids, base_path+\"train_preprocessed/\"+\"lab_id_%i.pkl\"%(i)) \n",
    "        print(\"Batch \", i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "arg = train_labels, train_files[0]\n",
    "a = preprocess(arg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Batches: 18\n",
      "Batch  0\n",
      "Batch  1\n",
      "Batch  2\n",
      "Batch  3\n",
      "Batch  4\n",
      "Batch  5\n",
      "Batch  6\n",
      "Batch  7\n",
      "Batch  8\n",
      "Batch  9\n",
      "Batch  10\n",
      "Batch  11\n",
      "Batch  12\n",
      "Batch  13\n",
      "Batch  14\n",
      "Batch  15\n",
      "Batch  16\n",
      "Batch  17\n",
      "CPU times: user 17min 29s, sys: 31min 40s, total: 49min 9s\n",
      "Wall time: 57min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dump_preprocess(train_files, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:diab_ret]",
   "language": "python",
   "name": "conda-env-diab_ret-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
